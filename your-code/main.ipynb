{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Avila Bible "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will explore the [**Avila Bible dataset**](https://archive.ics.uci.edu/ml/datasets/Avila) which has been extracted from 800 images of the 'Avila Bible', an XII century giant Latin copy of the Bible. The prediction task consists in associating each pattern to a copyist. You will use supervised learning algorithms to figure out what feature patterns each copyist are likely to have and use our model to predict those copyist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before your start:\n",
    "    - Read the README.md file,\n",
    "    - Comment as much as you can and use the APIla-bible in the README.md,\n",
    "    - Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your libraries\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![machine-learning](https://miro.medium.com/proxy/1*halC1X4ydv_3yHYxKqvrwg.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Avila data set has been extracted from 800 images of the the **Avila Bible**, a giant Latin copy of the whole Bible produced during the XII century between Italy and Spain. The palaeographic analysis of the  manuscript has  individuated the presence of 12 copyists. The pages written by each copyist are not equally numerous. \n",
    "Each pattern contains 10 features and corresponds to a group of 4 consecutive rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What am I expected to do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, your prediction task consists in associating each pattern to one of the 8 monks we will be evaluating (labeled as:  Marcus, Clarius, Philippus, Coronavirucus, Mongucus, Paithonius, Ubuntius, Esequlius). For that aim, you should: \n",
    "- Train a minimum of 4 different models\n",
    "- Perform a minimum of 4 Feature Extraction and Engineering techniques\n",
    "- Must contain a summary of the machine learning tools and algorithms\n",
    "- and the results or the score obtained with each of them\n",
    "\n",
    "You won't get much more instructions from now on. Remember to comment your code as much as you can. Keep the requirements in mind and have fun! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just one last piece of advice, take a moment to explore the data, remember this dataset contains two files: **train** and **test**. You will find both files in `data` folder. The **test** files contains the data you will predict for, therefore it does not include the labels.\n",
    "Use the **train** dataset as you wish, but don't forget to split it into **train** and **test** again so you can evaluate your models. Just be sure to train it again with the whole data before predicting.\n",
    "We have also included a **sample submission** which is of the exact shape and format you must use when evaluating your predictions against the groundtruth through the `APIla-bible`. It won't work unless it is the exact same shape. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('../data/training_dataset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.241386</td>\n",
       "      <td>0.109171</td>\n",
       "      <td>-0.127126</td>\n",
       "      <td>0.380626</td>\n",
       "      <td>0.172340</td>\n",
       "      <td>0.314889</td>\n",
       "      <td>0.484429</td>\n",
       "      <td>0.316412</td>\n",
       "      <td>0.188810</td>\n",
       "      <td>0.134922</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.303106</td>\n",
       "      <td>0.352558</td>\n",
       "      <td>0.082701</td>\n",
       "      <td>0.703981</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.391033</td>\n",
       "      <td>0.408929</td>\n",
       "      <td>1.045014</td>\n",
       "      <td>0.282354</td>\n",
       "      <td>-0.448209</td>\n",
       "      <td>Clarius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.116585</td>\n",
       "      <td>0.281897</td>\n",
       "      <td>0.175168</td>\n",
       "      <td>-0.152490</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.889332</td>\n",
       "      <td>0.371178</td>\n",
       "      <td>-0.024328</td>\n",
       "      <td>0.905984</td>\n",
       "      <td>-0.877830</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.326430</td>\n",
       "      <td>-0.652394</td>\n",
       "      <td>0.384996</td>\n",
       "      <td>-1.694222</td>\n",
       "      <td>-0.185173</td>\n",
       "      <td>-1.138481</td>\n",
       "      <td>-0.232828</td>\n",
       "      <td>-1.747116</td>\n",
       "      <td>-1.183175</td>\n",
       "      <td>-0.807380</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.437525</td>\n",
       "      <td>-0.471816</td>\n",
       "      <td>0.463236</td>\n",
       "      <td>-0.545248</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.972381</td>\n",
       "      <td>0.824183</td>\n",
       "      <td>-3.108388</td>\n",
       "      <td>-2.991700</td>\n",
       "      <td>-1.141030</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.241386  0.109171 -0.127126  0.380626  0.172340  0.314889  0.484429   \n",
       "1  0.303106  0.352558  0.082701  0.703981  0.261718 -0.391033  0.408929   \n",
       "2 -0.116585  0.281897  0.175168 -0.152490  0.261718 -0.889332  0.371178   \n",
       "3 -0.326430 -0.652394  0.384996 -1.694222 -0.185173 -1.138481 -0.232828   \n",
       "4 -0.437525 -0.471816  0.463236 -0.545248  0.261718 -0.972381  0.824183   \n",
       "\n",
       "          7         8         9         10  \n",
       "0  0.316412  0.188810  0.134922     Marcus  \n",
       "1  1.045014  0.282354 -0.448209    Clarius  \n",
       "2 -0.024328  0.905984 -0.877830  Philippus  \n",
       "3 -1.747116 -1.183175 -0.807380  Philippus  \n",
       "4 -3.108388 -2.991700 -1.141030  Philippus  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     float64\n",
       "1     float64\n",
       "2     float64\n",
       "3     float64\n",
       "4     float64\n",
       "5     float64\n",
       "6     float64\n",
       "7     float64\n",
       "8     float64\n",
       "9     float64\n",
       "10     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Marcus           5107\n",
       "Clarius          2362\n",
       "Philippus        1360\n",
       "Coronavirucus    1009\n",
       "Mongucus          640\n",
       "Paithonius        600\n",
       "Ubuntius          512\n",
       "Esequlius         427\n",
       "Name: 10, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['10'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv('../data/test_dataset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.017834</td>\n",
       "      <td>0.132725</td>\n",
       "      <td>0.125378</td>\n",
       "      <td>1.357345</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.190314</td>\n",
       "      <td>0.182426</td>\n",
       "      <td>0.445253</td>\n",
       "      <td>-0.715453</td>\n",
       "      <td>0.189796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.202992</td>\n",
       "      <td>-0.000745</td>\n",
       "      <td>-3.210528</td>\n",
       "      <td>-0.527256</td>\n",
       "      <td>0.082961</td>\n",
       "      <td>0.771662</td>\n",
       "      <td>0.144676</td>\n",
       "      <td>0.098572</td>\n",
       "      <td>0.251173</td>\n",
       "      <td>0.745333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.019049</td>\n",
       "      <td>0.211237</td>\n",
       "      <td>-0.155578</td>\n",
       "      <td>-0.311855</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.107265</td>\n",
       "      <td>0.484429</td>\n",
       "      <td>0.339303</td>\n",
       "      <td>-0.310094</td>\n",
       "      <td>-0.049630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.451232</td>\n",
       "      <td>-0.267686</td>\n",
       "      <td>0.335206</td>\n",
       "      <td>-0.831336</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.024215</td>\n",
       "      <td>0.220177</td>\n",
       "      <td>0.988787</td>\n",
       "      <td>0.032902</td>\n",
       "      <td>0.025485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.227680</td>\n",
       "      <td>0.109171</td>\n",
       "      <td>0.413447</td>\n",
       "      <td>0.118917</td>\n",
       "      <td>0.172340</td>\n",
       "      <td>0.480988</td>\n",
       "      <td>0.522180</td>\n",
       "      <td>0.091562</td>\n",
       "      <td>0.313536</td>\n",
       "      <td>0.256389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.017834  0.132725  0.125378  1.357345  0.261718  0.190314  0.182426   \n",
       "1 -0.202992 -0.000745 -3.210528 -0.527256  0.082961  0.771662  0.144676   \n",
       "2  1.019049  0.211237 -0.155578 -0.311855  0.261718  0.107265  0.484429   \n",
       "3  0.451232 -0.267686  0.335206 -0.831336  0.261718  0.024215  0.220177   \n",
       "4 -0.227680  0.109171  0.413447  0.118917  0.172340  0.480988  0.522180   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.445253 -0.715453  0.189796  \n",
       "1  0.098572  0.251173  0.745333  \n",
       "2  0.339303 -0.310094 -0.049630  \n",
       "3  0.988787  0.032902  0.025485  \n",
       "4  0.091562  0.313536  0.256389  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../data/sample_submission.csv', header=None, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ubuntius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Esequlius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coronavirucus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               1\n",
       "0               \n",
       "0      Philippus\n",
       "1       Ubuntius\n",
       "2      Esequlius\n",
       "3  Coronavirucus\n",
       "4      Philippus"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Keep calm and code on!`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge - train your models, make the best prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 1: Linear Models - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_dataset['10']\n",
    "X = train_dataset.drop(columns=[\"10\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carolina/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver=\"lbfgs\")\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Marcus           5965\n",
       "Coronavirucus     653\n",
       "Philippus         513\n",
       "Mongucus          384\n",
       "Clarius           347\n",
       "Paithonius        147\n",
       "Esequlius           3\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(y_pred)\n",
    "result[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"../data/result.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.576510234648028,\n",
       " 'quote': 'Nope, not good enough. But you shall rise as the glorious phoenix from the ashes of this score and get to the top!'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission = \"../data/result.csv\"\n",
    "with open(my_submission) as f:\n",
    "    res = requests.post(\"http://apila-bible.herokuapp.com/check\", files={\"csv_data\":f.read()})\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this model: \n",
    "#'accuracy': 0.576510234648028\n",
    "# Not good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 2: Nearest Neighbors - KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = neigh.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = pd.DataFrame(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2.to_csv(\"../data/result2.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7491263105341986,\n",
       " 'quote': \"Close, but no cigar. It's a good begining. How can you improve it more? Maybe try some different models?\"}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission = \"../data/result2.csv\"\n",
    "with open(my_submission) as f:\n",
    "    res = requests.post(\"http://apila-bible.herokuapp.com/check\", files={\"csv_data\":f.read()})\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this model: \n",
    "#'accuracy': 0.7491263105341986\n",
    "# It's getting better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 3: Decision Trees - DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = dt.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = pd.DataFrame(y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3.to_csv(\"../data/result3.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9757863205192212,\n",
       " 'quote': \"Great job! That's an impressive score. Will you give it an extra push? Almost at the top, care for a final `boost`?\"}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission = \"../data/result3.csv\"\n",
    "with open(my_submission) as f:\n",
    "    res = requests.post(\"http://apila-bible.herokuapp.com/check\", files={\"csv_data\":f.read()})\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this model: \n",
    "#'accuracy': 0.9757863205192212\n",
    "# That's an impressive score! Let's use one more model to check if this is the best we can get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 4: Naive Bayes - BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4 = clf.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result4 = pd.DataFrame(y_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result4.to_csv(\"../data/result4.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5089865202196705,\n",
       " 'quote': 'Nope, not good enough. But you shall rise as the glorious phoenix from the ashes of this score and get to the top!'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission = \"../data/result4.csv\"\n",
    "with open(my_submission) as f:\n",
    "    res = requests.post(\"http://apila-bible.herokuapp.com/check\", files={\"csv_data\":f.read()})\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this model: \n",
    "#'accuracy': 0.5089865202196705\n",
    "# That's not good. Let's keep the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 5: Ensemble - AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "ada = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred5 = ada.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result5 = pd.DataFrame(y_pred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result5.to_csv(\"../data/result5.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = \"../data/result5.csv\"\n",
    "with open(my_submission) as f:\n",
    "    res = requests.post(\"http://apila-bible.herokuapp.com/check\", files={\"csv_data\":f.read()})\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this model: \n",
    "#'accuracy': 0.5112331502745882\n",
    "# That's not good. I guess we should stop, because we already found a great accuracy with model 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do I do once I have a prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have already trained your model and made a prediction with it, you are ready to check what is the accuracy of it. \n",
    "\n",
    "Save your prediction as a `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THe best file we saved was: result3.to_csv(\"../data/result3.csv\", header=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to know the truth! Are you good enough to call yourself a pro?\n",
    "\n",
    "Lucky you have the ultimate **APIla-bible** which give you the chance of checking the accuracy of your predictions as many times as you need in order to become the pro you want to be. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do I post my prediction to the APIla-bible?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy peasy! You should only fulfil the path to your prediction `.csv` and run the cell below! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "my_submission = \"../data/sample_submission.csv\n",
    "with open(my_submission) as f:\n",
    "    res = requests.post(\"http://apila-bible.herokuapp.com/check\", files={\"csv_data\":f.read()})\n",
    "res.json()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best model was Decision Trees and the accuracy was 0.9739141288067898"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hope-you-enjoy](https://imgs.xkcd.com/comics/machine_learning.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
